{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from Aula1.Dataset import Dataset\n",
    "from Aula8.layer import Layer, SigmoidActivation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "        Retorna a 'accuracy' do modelo para um determinado dataset.\n",
    "    \"\"\"\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def mse(true_labels: np.ndarray, predicted_labels: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "        Calcula e retorna o Erro Quadrado Médio do modelo num dataset.\n",
    "    \"\"\"\n",
    "    return np.sum((true_labels - predicted_labels) ** 2) / (len(true_labels) * 2)\n",
    "\n",
    "\n",
    "def mse_deriv(true_labels: np.ndarray, predicted_labels: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Retorna a derivada do Erro Quadrado Médio para a variável predicted_labels.\n",
    "    \"\"\"\n",
    "    return -2 * (true_labels - predicted_labels) / (len(true_labels) * 2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP\n",
    "Modelo de Rede Neuronal com várias camadas.\n",
    "\n",
    "-    A lista de camadas passada como parâmetro para a inicialização da classe inclui a camada de entrada, a camada intermediária e a camada de saída.  \n",
    "-    O método de ajuste ('fit') implementa a propagação para frente nas camadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self,\n",
    "                 layers: list,\n",
    "                 epochs: int = 1000,\n",
    "                 learning_rate: float = 0.01,\n",
    "                 loss: Callable = mse,\n",
    "                 loss_derivative: Callable = mse_deriv,\n",
    "                 verbose: bool = False):\n",
    "        \n",
    "        # parametros\n",
    "        self.layers = layers   \n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.loss = loss                        # funcao de loss\n",
    "        self.loss_derivative = loss_derivative  # derivada da funcao de loss\n",
    "        self.verbose = verbose                  # se é para imprimir a loss em cada epoch\n",
    "\n",
    "    def fit(self, dataset: Dataset) -> 'MLP':\n",
    "        \"\"\"\n",
    "            Ajustar o modelo para o dataset dado.\n",
    "        \"\"\"\n",
    "        X = dataset.X\n",
    "        y = dataset.y\n",
    "        \n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "\n",
    "            # forward propagation\n",
    "            for layer in self.layers:\n",
    "                X = layer.forward(X)\n",
    "\n",
    "            # backward propagation\n",
    "            #error = self.loss_derivative(y, X)\n",
    "            #for layer in self.layers[::-1]:\n",
    "            #    error = layer.backward(error, self.learning_rate)\n",
    "        \n",
    "            # calculate cost\n",
    "            cost = self.loss(y, X)\n",
    "\n",
    "            # print loss\n",
    "            if self.verbose:\n",
    "                print(f'Epoch {epoch}/{self.epochs} - cost: {cost}')\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, dataset: Dataset) -> np.ndarray:\n",
    "        \"\"\"\n",
    "            Prever o output do dataset.\n",
    "            Retorna um array (prediction)\n",
    "        \"\"\"\n",
    "        X = dataset.X\n",
    "\n",
    "        # forward propagation\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "\n",
    "        return X\n",
    "    \n",
    "\n",
    "    def cost(self, dataset: Dataset) -> float:\n",
    "        \"\"\"\n",
    "            Computar o custo do modelo no dataset dado.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(dataset)\n",
    "        return self.loss(dataset.y, y_pred)\n",
    "\n",
    "    def score(self, dataset: Dataset, scoring_func: Callable = accuracy) -> float:\n",
    "        \"\"\"\n",
    "            Computar o score do modelo no dataset dado.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(dataset)\n",
    "        return scoring_func(dataset.y, y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.inputs:  (4, 2)\n",
      "self.weights:  (2, 2)\n",
      "self.inputs:  (4, 2)\n",
      "self.weights:  (2, 1)\n",
      "Predictions:  [[9.99954561e-01]\n",
      " [4.54803785e-05]\n",
      " [4.54803785e-05]\n",
      " [9.99954561e-01]]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    X = np.array([[0, 0],\n",
    "                  [0, 1],\n",
    "                  [1, 0],\n",
    "                  [1, 1]])\n",
    "\n",
    "    y = np.array([[1],\n",
    "                  [0],\n",
    "                  [0],\n",
    "                  [1]])\n",
    "\n",
    "    # XNOR problem is a binary classification problem\n",
    "    dataset = Dataset(X, y, features=['x1', 'x2'], label='X1 XNOR X2')\n",
    "    dataset.to_dataframe()\n",
    "\n",
    "   # weights for Dense Layer 1\n",
    "    w1 = np.array([[20, -20],\n",
    "                [20, -20]])\n",
    "    b1 = np.array([[-30, 10]])\n",
    "\n",
    "    l1 = Layer(input_size=2, output_size=2)\n",
    "    l1.weights = w1\n",
    "    l1.bias = b1\n",
    "\n",
    "\n",
    "    # weights for Dense Layer 2\n",
    "\n",
    "    w2 = np.array([[20],\n",
    "                [20]])\n",
    "    b2 = np.array([[-10]])\n",
    "\n",
    "    l2 = Layer(input_size=2, output_size=1)\n",
    "    l2.weights = w2\n",
    "    l2.bias = b2\n",
    "\n",
    "    l1_sg = SigmoidActivation()\n",
    "    l2_sg = SigmoidActivation()\n",
    "\n",
    "    # MLP\n",
    "    model = MLP(layers=[l1, l1_sg, l2, l2_sg])\n",
    "\n",
    "    #print(\"Fit: \", model.fit(dataset))\n",
    "    print(\"Predictions: \", model.predict(dataset))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
