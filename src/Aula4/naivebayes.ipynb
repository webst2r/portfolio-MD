{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from math import log\n",
    "import random\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DiscreteFeatureVectors:\n",
    "    \"\"\"Collection of discrete feature vectors.\"\"\"\n",
    "\n",
    "    def __init__(self, use_smoothing):\n",
    "        \"\"\"Construct a container for discrete feature vectors.\n",
    "\n",
    "        :param use_smoothing: A boolean to indicate whether to use smoothing.\n",
    "        \"\"\"\n",
    "        self.use_laplace_smoothing = use_smoothing\n",
    "        self.possible_categories = defaultdict(set)\n",
    "        self.frequencies = defaultdict(lambda: defaultdict(lambda: Counter()))\n",
    "\n",
    "    def add(self, label, index, feature):\n",
    "        self.frequencies[label][index][feature.value] += 1\n",
    "        self.possible_categories[index].add(feature.value)\n",
    "\n",
    "    def probability(self, label, index, feature, num_label_instances):\n",
    "        \"\"\"Calculate probability with Laplace smoothing optionally.\"\"\"\n",
    "        frequency = self.frequencies[label][index][feature.value]\n",
    "        frequency += 1 if self.use_laplace_smoothing else 0\n",
    "\n",
    "        num_classes = len(self.possible_categories[index])\n",
    "        num_label_instances += num_classes if self.use_laplace_smoothing else 0\n",
    "        return frequency / num_label_instances\n",
    "\n",
    "\n",
    "class DiscreteFeature:\n",
    "    def __init__(self, value):\n",
    "        self.value = value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, extract_features, use_smoothing=True):\n",
    "        \"\"\"Create a naive bayes classifier.\n",
    "\n",
    "        :param extract_features: Callback to map a feature vector to discrete and continuous features.\n",
    "        :param use_smoothing: Whether to use smoothing when calculating probability.\n",
    "        \"\"\"\n",
    "        self.priors = defaultdict(dict)\n",
    "\n",
    "        self.label_counts = Counter()\n",
    "        self.discrete_feature_vectors = DiscreteFeatureVectors(use_smoothing)\n",
    "        self._extract_features = extract_features\n",
    "        self._is_fitted = False\n",
    "\n",
    "    def fit(self, design_matrix, target_values):\n",
    "        \"\"\"Fit model according to design matrix and target values.\"\"\"\n",
    "        for i, training_example in enumerate(design_matrix):\n",
    "            label = target_values[i]\n",
    "            self.label_counts[label] += 1\n",
    "            features = self._extract_features(training_example)\n",
    "            for j, feature in enumerate(features):\n",
    "                self.discrete_feature_vectors.add(label, j, feature)\n",
    "\n",
    "        total_num_records = len(target_values)\n",
    "        for label in set(target_values):\n",
    "            self.priors[label] = self.label_counts[label] / total_num_records\n",
    "\n",
    "        self._is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, test_set):\n",
    "        \"\"\"Predict target values for test set.\"\"\"\n",
    "        self._check_is_fitted()\n",
    "\n",
    "        predictions = []\n",
    "        for i in range(len(test_set)):\n",
    "            result = self.predict_record(test_set[i])\n",
    "            predictions.append(result)\n",
    "        return predictions\n",
    "\n",
    "    def predict_record(self, test_record):\n",
    "        \"\"\"Predict the label for the test record.\"\"\"\n",
    "        self._check_is_fitted()\n",
    "\n",
    "        log_likelihood = {k: log(v) for k, v in self.priors.items()}\n",
    "        for label in self.label_counts:\n",
    "            features = self._extract_features(test_record)\n",
    "            for i, feature in enumerate(features):\n",
    "                probability = self._get_probability(i, feature, label)\n",
    "                try:\n",
    "                    log_likelihood[label] += log(probability)\n",
    "                except ValueError as e:\n",
    "                    raise ValueError(\"Error occurred while computing log likelihood\")\n",
    "\n",
    "        return max(log_likelihood, key=log_likelihood.get)\n",
    "\n",
    "    def _check_is_fitted(self):\n",
    "        if not self._is_fitted:\n",
    "            raise ValueError(\"This instance has not been fitted yet.\")\n",
    "\n",
    "    def _get_probability(self, feature_index, feature, label):\n",
    "        probability = self.discrete_feature_vectors.probability(label, feature_index, feature, self.label_counts[label])\n",
    "        return probability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestNaiveBayesWithBinaryDataset:\n",
    "    \"\"\"Test the Naive Bayes classifier with a toy binary dataset.\"\"\"\n",
    "\n",
    "    def setUpClass(cls):\n",
    "        dataset = cls.get_toy_binary_dataset()\n",
    "        cls.design_matrix = [row[:-1] for row in dataset]\n",
    "        cls.target_values = [row[-1] for row in dataset]\n",
    "\n",
    "    def test_predict_record_with_binary_dataset(self):\n",
    "        expected_prediction = 1\n",
    "\n",
    "        test_record = [1, 1, 0]\n",
    "        clf = NaiveBayes(self.extract_features)\n",
    "        clf.fit(self.design_matrix, self.target_values)\n",
    "        prediction = clf.predict_record(test_record)\n",
    "\n",
    "        if expected_prediction == prediction:\n",
    "            print(\"Test passed: Predicted label matches the expected label.\")\n",
    "        else:\n",
    "            print(\"Test failed: Predicted label does not match the expected label.\")\n",
    "\n",
    "    def test_zero_observations_error(self):\n",
    "        clf = NaiveBayes(self.extract_features, use_smoothing=False)\n",
    "        clf.fit(self.design_matrix, self.target_values)\n",
    "\n",
    "        test_record = [0, 1, 0]\n",
    "        try:\n",
    "            clf.predict_record(test_record)\n",
    "        except:\n",
    "            print(\"Test passed: Zero observations error was handled.\")\n",
    "        else:\n",
    "            print(\"Test failed: Zero observations error was not raised.\")\n",
    "\n",
    "    def test_accuracy(self):\n",
    "        clf = NaiveBayes(self.extract_features)\n",
    "        clf.fit(self.design_matrix, self.target_values)\n",
    "\n",
    "        test_records = [\n",
    "            [1, 1, 0],\n",
    "            [0, 1, 0],\n",
    "            [1, 0, 0],\n",
    "            [0, 0, 1]\n",
    "        ]\n",
    "        expected_labels = [1, 0, 1, 0]\n",
    "\n",
    "        predictions = clf.predict(test_records)\n",
    "\n",
    "        correct = sum(1 for pred, expected in zip(predictions, expected_labels) if pred == expected)\n",
    "        accuracy = correct / len(expected_labels) * 100\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(\"Predictions:\", predictions)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_features(feature_vector):\n",
    "        return [\n",
    "            DiscreteFeature(feature_vector[0]),\n",
    "            DiscreteFeature(feature_vector[1]),\n",
    "            DiscreteFeature(feature_vector[2]),\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_toy_binary_dataset():\n",
    "        \"\"\"The third with value 0 is never observed with class 0.\n",
    "\n",
    "        This is called the zero observations problem,\n",
    "        and is dealt with by additive smoothing.\n",
    "        \"\"\"\n",
    "        return [\n",
    "            [0, 0, 1, 0],\n",
    "            [0, 1, 1, 0],\n",
    "            [0, 1, 1, 0],\n",
    "            [1, 0, 1, 0],\n",
    "            [1, 0, 1, 0],\n",
    "            [0, 0, 0, 1],\n",
    "            [0, 0, 1, 1],\n",
    "            [1, 0, 1, 1],\n",
    "            [1, 1, 1, 1],\n",
    "            [1, 0, 1, 1],\n",
    "        ]\n",
    "\n",
    "\n",
    "class TestNaiveBayesWithLargeDataset:\n",
    "    \"\"\"Test the Naive Bayes classifier with a large discrete values dataset.\"\"\"\n",
    "\n",
    "    def setUpClass(cls):\n",
    "        dataset = cls.get_large_discrete_dataset()\n",
    "        cls.design_matrix = [row[:-1] for row in dataset]\n",
    "        cls.target_values = [row[-1] for row in dataset]\n",
    "\n",
    "    def test_predict_record_with_large_dataset(self):\n",
    "        test_dataset = self.get_large_discrete_dataset()\n",
    "        test_records = [row[:-1] for row in test_dataset]\n",
    "        expected_labels = [row[-1] for row in test_dataset]\n",
    "\n",
    "        clf = NaiveBayes(self.extract_features)\n",
    "        clf.fit(self.design_matrix, self.target_values)\n",
    "        predictions = clf.predict(test_records)\n",
    "\n",
    "        correct_predictions = sum(1 for pred, exp in zip(predictions, expected_labels) if pred == exp)\n",
    "        accuracy = correct_predictions / len(predictions) * 100\n",
    "\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        print(\"Predicted\\tExpected\")\n",
    "        for pred, exp in zip(predictions, expected_labels):\n",
    "            print(f\"{pred}\\t\\t{exp}\")\n",
    "\n",
    "        if correct_predictions == len(predictions):\n",
    "            print(\"Test passed: All predictions match the expected labels.\")\n",
    "        else:\n",
    "            print(\"Some predictions do not match the expected labels.\")\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_features(feature_vector):\n",
    "        return [\n",
    "            DiscreteFeature(feature_vector[0]),\n",
    "            DiscreteFeature(feature_vector[1]),\n",
    "            DiscreteFeature(feature_vector[2]),\n",
    "            DiscreteFeature(feature_vector[3]),\n",
    "            DiscreteFeature(feature_vector[4]),\n",
    "            DiscreteFeature(feature_vector[5]),\n",
    "        ]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_large_discrete_dataset():\n",
    "        \"\"\"Generate a large discrete values dataset.\"\"\"\n",
    "        dataset = []\n",
    "        num_instances = 1000  # Number of instances in the dataset\n",
    "\n",
    "        for _ in range(num_instances):\n",
    "            row = []\n",
    "            for _ in range(6):  # Number of features in each instance\n",
    "                # Generate random discrete values between 0 and 1\n",
    "                value = random.randint(0, 1)\n",
    "                row.append(value)\n",
    "            # Add a random label (0 or 1) at the end\n",
    "            label = random.randint(0, 1)\n",
    "            row.append(label)\n",
    "            dataset.append(row)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NaiveBayes with Binary Dataset\n",
      "Test passed: Predicted label matches the expected label.\n",
      "Test passed: Zero observations error was handled.\n",
      "Accuracy: 100.00%\n",
      "Predictions: [1, 0, 1, 0]\n",
      "\n",
      "\n",
      "Test NaiveBayes with Large Dataset\n",
      "Accuracy: 48.60%\n",
      "Predicted\tExpected\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "0\t\t0\n",
      "0\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "0\t\t1\n",
      "0\t\t0\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t0\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t1\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t0\n",
      "1\t\t1\n",
      "1\t\t1\n",
      "0\t\t1\n",
      "1\t\t0\n",
      "Some predictions do not match the expected labels.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"Test NaiveBayes with Binary Dataset\")\n",
    "    test_case = TestNaiveBayesWithBinaryDataset()\n",
    "    test_case.setUpClass()\n",
    "    test_case.test_predict_record_with_binary_dataset()\n",
    "    test_case.test_zero_observations_error()\n",
    "    test_case.test_accuracy()\n",
    "\n",
    "    print(\"\\n\\nTest NaiveBayes with Large Dataset\")\n",
    "    test_case = TestNaiveBayesWithLargeDataset()\n",
    "    test_case.setUpClass()\n",
    "    test_case.test_predict_record_with_large_dataset()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
